## 2. AngelHack Hackathon (in partnership with S.I.H.): Real-Time Support Chatbot (team of 3)

> My Role: I led the development of the application. I focused on product strategy, ensuring accessibility, legal compliance, and user-centric development, while refining the chatbot’s tone and response style based on user feedback and engagement metrics.

- **Technical Execution**: Built a chatbot for real-time mental health support and crisis intervention. Used Google Dialogflow for natural language processing to understand user messages and intent. The backend included cloud-based microservices that could escalate high-severity cases to human counselors in real time. We integrated Twilio’s API to enable SMS support for users without the app, and utilized Google Firebase for secure storage of chat transcripts and user preferences.  

- **Product Strategy & Market Fit**: Positioned the chatbot as an accessible first-line support system for mental health, available 24/7 to supplement professional help. Validated the concept through a quick competitive analysis of existing mental wellness apps and helplines, ensuring our solution filled a gap in immediacy and personalization. To explore sustainability, we outlined a freemium monetization model - the base chatbot service is free, while a premium tier could offer direct therapist matching or weekly check-in calls. We also defined OKRs to guide success (e.g., average response time under 5 seconds for the chatbot, maintain 80%+ user satisfaction based on feedback surveys).  

- **Data-Driven Decision-Making**: Incorporated A/B testing during development to refine the chatbot’s tone and response style (for instance, testing a casual empathetic tone versus a more formal supportive tone to see which engaged users better). Tracked user engagement metrics such as session duration, number of messages per session, and conversation completion rates. Performed a simple cohort analysis by categorizing users based on self-reported stress levels or crisis type; this allowed us to tailor the resources and recommended coping exercises the chatbot provided for different user needs. Insights from usage data informed tweaks to the dialogue flow - for example, if users in academic stress scenarios dropped off early, we adjusted the bot’s prompts to better guide them.  

- **Leadership & Collaboration**: Led the team’s market research and oversaw legal compliance considerations for handling sensitive personal data. Ensured our engineers implemented secure data practices (like end-to-end encryption for messages and proper user consent flows) to align with HIPAA and GDPR guidelines, given the confidential nature of mental health conversations. Collaborated closely with a teammate focused on UX design to craft an empathetic conversational flow and a calming interface (choosing reassuring language and friendly avatars). In the hackathon demo to judges, we emphasized not just the technical innovation but also ethical AI use - clarifying how the bot avoids giving medical advice beyond its scope and hands off to human experts when necessary.  

- **User-Centric Development**: Created detailed user personas to guide development, such as a college student coping with exam stress and a young professional dealing with anxiety. These personas helped in shaping the chatbot’s dialogue - for example, the college student persona led us to include study-break reminders and campus counseling info as resources. We tested the chatbot informally with a small group of peers acting as users in distress to gather qualitative feedback. This testing led to improvements like adding quick-feedback prompts ("Was this advice helpful?") at the end of a session and tweaking the bot’s responses to sound more compassionate and less generic. The end result was a chatbot experience designed with genuine user voices in mind.  
